{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d1ebe5-d8fe-4707-9f9a-b8ba3fa5ffae",
   "metadata": {},
   "source": [
    "Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions. \n",
    "\n",
    "Q2. Load the Wine Quality dataset and explore its dimensions.  \n",
    "\n",
    "Dataset link:  \n",
    "https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification \n",
    "\n",
    "Q3. Check for null values, identify categorical variables, and encode them. \n",
    "\n",
    "Q4. Separate the features and target variables from the dataset. \n",
    "\n",
    "Q5. Perform a train-test split, dividing the data into training, validation, and test datasets. Q6. Scale the \n",
    "dataset using an appropriate scaling technique. \n",
    "\n",
    "Q7. Design and implement at least two hidden layers and an output layer for the binary categorical  \n",
    "variables. \n",
    "\n",
    "Q8. Create a Sequential model in Keras and add the previously designed layers to it. Q9. Print the summary of the model architecture. \n",
    "\n",
    "Q10. Set the loss function(‘binary_crossentropy’), optimizer, and include the accuracy metric in the model. \n",
    "\n",
    "Q11. Compile the model with the specified loss function, optimizer, and metrics. \n",
    "\n",
    "Q12. Fit the model to the training data using appropriate batch size and number of epochs. Q13. Obtain the model's parameters (weights and biases). \n",
    "\n",
    "Q14. Store the model's training history as a Pandas DataFrame. \n",
    "\n",
    "Q15. Plot the training history (e.g., accuracy and loss) using suitable visualization techniques.\n",
    "\n",
    "Q16. Evaluate the model's performance using the test dataset and report relevant metrics. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1d45f-eb45-4b0b-a189-ca6afd6adc38",
   "metadata": {},
   "source": [
    "Q1. Install and load the latest versions of TensorFlow and Keras:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "```\n",
    "\n",
    "Q2. Load the Wine Quality dataset and explore its dimensions:\n",
    "\n",
    "Download the Wine Quality dataset from the provided link and load it into a Pandas DataFrame:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the dataset is stored in a CSV file named wine_quality.csv\n",
    "data = pd.read_csv('wine_quality.csv')\n",
    "\n",
    "# Explore the dimensions of the dataset\n",
    "print(data.shape)\n",
    "```\n",
    "\n",
    "Q3. Check for null values, identify categorical variables, and encode them:\n",
    "\n",
    "```python\n",
    "# Check for null values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Identify categorical variables (if any)\n",
    "categorical_vars = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Perform one-hot encoding on categorical variables (if any)\n",
    "if len(categorical_vars) > 0:\n",
    "    data = pd.get_dummies(data, columns=categorical_vars, drop_first=True)\n",
    "```\n",
    "\n",
    "Q4. Separate the features and target variables from the dataset:\n",
    "\n",
    "```python\n",
    "X = data.drop('target_column_name', axis=1)  # Replace 'target_column_name' with the actual target column\n",
    "y = data['target_column_name']  # Replace 'target_column_name' with the actual target column\n",
    "```\n",
    "\n",
    "Q5. Perform a train-test split, dividing the data into training, validation, and test datasets:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training data into training and validation sets (80% training, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "Q6. Scale the dataset using an appropriate scaling technique:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform the training, validation, and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "Q7. Design and implement at least two hidden layers and an output layer for the binary categorical variables:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Assuming you have the number of input features as 'input_dim'\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "# Create the Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add the hidden layers\n",
    "model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "```\n",
    "\n",
    "Q8. Create a Sequential model in Keras and add the previously designed layers to it:\n",
    "\n",
    "The code in Q7 already does this.\n",
    "\n",
    "Q9. Print the summary of the model architecture:\n",
    "\n",
    "```python\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "Q10. Set the loss function ('binary_crossentropy'), optimizer, and include the accuracy metric in the model:\n",
    "\n",
    "```python\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "Q11. Compile the model with the specified loss function, optimizer, and metrics:\n",
    "\n",
    "The code in Q10 already does this.\n",
    "\n",
    "Q12. Fit the model to the training data using an appropriate batch size and number of epochs:\n",
    "\n",
    "```python\n",
    "# Assuming you have defined 'X_train_scaled', 'y_train', 'X_val_scaled', 'y_val'\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
    "```\n",
    "\n",
    "Q13. Obtain the model's parameters (weights and biases):\n",
    "\n",
    "```python\n",
    "model_params = model.get_weights()\n",
    "```\n",
    "\n",
    "Q14. Store the model's training history as a Pandas DataFrame:\n",
    "\n",
    "```python\n",
    "history_df = pd.DataFrame(history.history)\n",
    "```\n",
    "\n",
    "Q15. Plot the training history (e.g., accuracy and loss) using suitable visualization techniques:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history_df['loss'], label='Training Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Q16. Evaluate the model's performance using the test dataset and report relevant metrics:\n",
    "\n",
    "```python\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6900f2-3fbc-4ddb-b81a-8c370b3734d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
